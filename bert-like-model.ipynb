{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-01-04T06:53:55.149763Z",
     "iopub.status.busy": "2021-01-04T06:53:55.148881Z",
     "iopub.status.idle": "2021-01-04T06:53:55.174588Z",
     "shell.execute_reply": "2021-01-04T06:53:55.173820Z"
    },
    "papermill": {
     "duration": 0.041546,
     "end_time": "2021-01-04T06:53:55.174729",
     "exception": false,
     "start_time": "2021-01-04T06:53:55.133183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/.DS_Store\n",
      "../input/riiid-test-answer-prediction/lectures.csv\n",
      "../input/riiid-test-answer-prediction/.DS_Store\n",
      "../input/riiid-test-answer-prediction/example_sample_submission.csv\n",
      "../input/riiid-test-answer-prediction/train_tiny.csv\n",
      "../input/riiid-test-answer-prediction/questions.csv\n",
      "../input/riiid-test-answer-prediction/train.csv\n",
      "../input/riiid-test-answer-prediction/example_test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('../input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-01-04T06:53:55.201255Z",
     "iopub.status.busy": "2021-01-04T06:53:55.200529Z",
     "iopub.status.idle": "2021-01-04T06:57:02.535231Z",
     "shell.execute_reply": "2021-01-04T06:57:02.534108Z"
    },
    "papermill": {
     "duration": 187.352131,
     "end_time": "2021-01-04T06:57:02.535369",
     "exception": false,
     "start_time": "2021-01-04T06:53:55.183238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number skills 13523\n",
      "number skills 13523\n",
      "CPU times: user 1min 36s, sys: 19.5 s, total: 1min 55s\n",
      "Wall time: 2min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import gc\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "def seed_everything(seed = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "#     torch.set_deterministic(False)\n",
    "seed_everything()\n",
    "\n",
    "dtype = {'timestamp': 'int64', 'user_id': 'int32' ,'content_id': 'int16','content_type_id': 'int8','answered_correctly':'int8'}\n",
    "\n",
    "train_df = pd.read_csv('../input/riiid-test-answer-prediction/train.csv', usecols=[1, 2, 3, 4, 5, 7], dtype=dtype)\n",
    "\n",
    "train_df = train_df[train_df.content_type_id == False]\n",
    "del train_df['content_type_id']\n",
    "gc.collect()\n",
    "train_df = train_df.sort_values(['timestamp'], ascending=True).reset_index(drop = True)\n",
    "\n",
    "questions = pd.read_csv('../input/riiid-test-answer-prediction/questions.csv')\n",
    "dict_tags = {}\n",
    "for i, tags in enumerate(questions['tags'].unique()):\n",
    "    if tags in dict_tags.keys():\n",
    "        continue\n",
    "    dict_tags[tags] = i\n",
    "questions.tags.replace(dict_tags, inplace=True)\n",
    "questions.part = questions.part.astype(np.int8)\n",
    "questions.tags = questions.tags.astype(np.int16)\n",
    "skills = questions[\"question_id\"].unique()\n",
    "n_skill = len(skills)\n",
    "print(\"number skills\", len(skills))\n",
    "questions.rename(columns = {'question_id': 'content_id'}, inplace=True)\n",
    "train_df = train_df.merge(questions[['content_id', 'part', 'tags']], on='content_id', how='left')\n",
    "skills = questions[\"content_id\"].unique()\n",
    "n_skill = len(skills)\n",
    "print(\"number skills\", len(skills))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T06:57:02.560891Z",
     "iopub.status.busy": "2021-01-04T06:57:02.559739Z",
     "iopub.status.idle": "2021-01-04T06:58:43.076562Z",
     "shell.execute_reply": "2021-01-04T06:58:43.076002Z"
    },
    "papermill": {
     "duration": 100.531671,
     "end_time": "2021-01-04T06:58:43.076676",
     "exception": false,
     "start_time": "2021-01-04T06:57:02.545005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.6 s, sys: 4.71 s, total: 51.3 s\n",
      "Wall time: 51.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "group = train_df.groupby('user_id').apply(lambda r: (\n",
    "        r['content_id'].values,\n",
    "        r['answered_correctly'].values,\n",
    "        r['task_container_id'].values,\n",
    "        r['timestamp'].values,\n",
    "        r['part'].values,\n",
    "        r['tags'].values\n",
    "        ))\n",
    "del train_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T06:58:43.100413Z",
     "iopub.status.busy": "2021-01-04T06:58:43.099776Z",
     "iopub.status.idle": "2021-01-04T06:58:43.103334Z",
     "shell.execute_reply": "2021-01-04T06:58:43.104077Z"
    },
    "papermill": {
     "duration": 0.017914,
     "end_time": "2021-01-04T06:58:43.104196",
     "exception": false,
     "start_time": "2021-01-04T06:58:43.086282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_SEQ = 180\n",
    "ACCEPTED_USER_CONTENT_SIZE = 4\n",
    "EMBED_SIZE = 128\n",
    "BATCH_SIZE = 64\n",
    "DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T06:58:43.132884Z",
     "iopub.status.busy": "2021-01-04T06:58:43.131957Z",
     "iopub.status.idle": "2021-01-04T06:58:43.157966Z",
     "shell.execute_reply": "2021-01-04T06:58:43.158437Z"
    },
    "papermill": {
     "duration": 0.044584,
     "end_time": "2021-01-04T06:58:43.158576",
     "exception": false,
     "start_time": "2021-01-04T06:58:43.113992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self, state_size=200):\n",
    "        super(FFN, self).__init__()\n",
    "        self.state_size = state_size\n",
    "\n",
    "        self.lr1 = nn.Linear(state_size, state_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lr2 = nn.Linear(state_size, state_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.lr1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.lr2(x)\n",
    "        return self.dropout(x)\n",
    "\n",
    "def future_mask(shape):\n",
    "    future_mask = np.triu(np.ones(shape), k=1).astype('bool')\n",
    "    return torch.from_numpy(future_mask)\n",
    "\n",
    "class SubLayer(nn.Module):\n",
    "    def __init__(self,embed_dim):\n",
    "        super().__init__()\n",
    "        self.multi_att = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=8, dropout=0.2)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.layer_normal = nn.LayerNorm(embed_dim) \n",
    "\n",
    "        self.ffn = FFN(embed_dim)\n",
    "    def forward(self, e, x):\n",
    "        att_mask = future_mask(shape=(e.size(0), x.size(0))).to(device)\n",
    "        att_output, att_weight = self.multi_att(e, x, x, attn_mask=att_mask)\n",
    "        att_output = self.layer_normal(att_output + e)\n",
    "        att_output = att_output.permute(1, 0, 2) # att_output: [s_len, bs, embed] => [bs, s_len, embed]\n",
    "\n",
    "        x = self.ffn(att_output)\n",
    "        x = self.layer_normal(x + att_output)\n",
    "        return x, att_weight\n",
    "class BERTModel(nn.Module):\n",
    "    def __init__(self, n_skill, max_seq=MAX_SEQ, embed_dim=128):\n",
    "        super().__init__()\n",
    "        self.pos_embedding = nn.Embedding(max_seq, embed_dim)\n",
    "        self.embedding = nn.Embedding(n_skill+1, embed_dim)\n",
    "        self.ans_embedding = nn.Embedding(3, embed_dim)\n",
    "        self.time_embedding = nn.Embedding(10000, embed_dim)\n",
    "        self.lag_time_embedding = nn.Embedding(3600, embed_dim)\n",
    "        self.elapsed_time_embedding = nn.Embedding(1520, embed_dim)\n",
    "        self.part_embedding = nn.Embedding(8, embed_dim)\n",
    "        \n",
    "        self.sub1 = SubLayer(embed_dim)\n",
    "        \n",
    "        self.fc = nn.Linear(embed_dim, embed_dim*2)\n",
    "        self.fc1 = nn.Linear(embed_dim*5, embed_dim)\n",
    "        \n",
    "        self.bacth_norm = nn.BatchNorm1d(max_seq)\n",
    "        self.bacth_norm1 = nn.BatchNorm1d(max_seq)\n",
    "        \n",
    "        self.pred = nn.Linear(embed_dim*2, 1)\n",
    "        \n",
    "    def forward(self, history_question, history_answer, time, lag_time, part, elapsed_time):\n",
    "        device = history_question.device\n",
    "        history_answer = history_answer\n",
    "        history_answer = self.ans_embedding(history_answer)\n",
    "        \n",
    "        x = self.embedding(history_question)\n",
    "        pos_id = torch.arange(x.size(1)).unsqueeze(0).to(device)\n",
    "        pos_x = self.pos_embedding(pos_id)\n",
    "        time_x = self.time_embedding(time)\n",
    "        lag_time = self.lag_time_embedding(lag_time)\n",
    "        part = self.part_embedding(part)\n",
    "        elapsed_time = self.elapsed_time_embedding(elapsed_time)\n",
    "        \n",
    "        history_answer += pos_x\n",
    "        x += history_answer\n",
    "        time_x += history_answer\n",
    "        lag_time += history_answer\n",
    "        part += history_answer\n",
    "        elapsed_time += history_answer\n",
    "        x = torch.cat([x, time_x, lag_time, part, elapsed_time], axis=-1)\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        \n",
    "        x = x.permute(1, 0, 2) # x: [bs, s_len, embed] => [s_len, bs, embed]\n",
    "        x, att_weight= self.sub1(x, x)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        x = self.bacth_norm(x)\n",
    "\n",
    "        x = self.pred(x)\n",
    "        \n",
    "        return x.squeeze(-1), att_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T06:58:43.566062Z",
     "iopub.status.busy": "2021-01-04T06:58:43.565312Z",
     "iopub.status.idle": "2021-01-04T06:58:48.290524Z",
     "shell.execute_reply": "2021-01-04T06:58:48.289260Z"
    },
    "papermill": {
     "duration": 5.122044,
     "end_time": "2021-01-04T06:58:48.290690",
     "exception": false,
     "start_time": "2021-01-04T06:58:43.168646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/v9-test/7901_bert_v4.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-238c5be0b5c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/v9-test/7901_bert_v4.pth'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/v9-test/7901_bert_v4.pth'"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.load('/kaggle/input/v9-test/7901_bert_v4.pth',  map_location=lambda storage, loc: storage.cuda(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T06:58:48.341110Z",
     "iopub.status.busy": "2021-01-04T06:58:48.339051Z",
     "iopub.status.idle": "2021-01-04T06:58:48.341960Z",
     "shell.execute_reply": "2021-01-04T06:58:48.342561Z"
    },
    "papermill": {
     "duration": 0.039839,
     "end_time": "2021-01-04T06:58:48.342694",
     "exception": false,
     "start_time": "2021-01-04T06:58:48.302855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, samples, test_df, skills, max_seq=MAX_SEQ):\n",
    "        super(TestDataset, self).__init__()\n",
    "        self.samples = samples\n",
    "        self.user_ids = [x for x in test_df[\"user_id\"].unique()]\n",
    "        self.test_df = test_df\n",
    "        self.skills = skills\n",
    "        self.n_skill = len(skills)\n",
    "        self.max_seq = max_seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.test_df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        test_info = self.test_df.iloc[index]\n",
    "\n",
    "        user_id = test_info[\"user_id\"]\n",
    "        target_id = test_info[\"content_id\"]\n",
    "        target_task = test_info[\"task_container_id\"]\n",
    "        target_timestamp = test_info[\"timestamp\"]\n",
    "        target_part = test_info['part']\n",
    "        target_tags = test_info['tags']\n",
    "        \n",
    "    \n",
    "        q = np.zeros(self.max_seq, dtype=int)\n",
    "        qa = np.zeros(self.max_seq, dtype=int)\n",
    "        task = np.zeros(self.max_seq, dtype=int)\n",
    "        lag_time = np.zeros(self.max_seq, dtype=int)\n",
    "        part = np.zeros(self.max_seq, dtype=int)\n",
    "        tags = np.zeros(self.max_seq, dtype=int)\n",
    "        \n",
    "        target_lag_time = 0\n",
    "        if user_id in self.samples.index:\n",
    "            q_, qa_, task_, timestamp_, part_, tags_ = self.samples[user_id]\n",
    "            \n",
    "            ##获取lag_time\n",
    "            lag_time_ = (np.diff(timestamp_)/1000)\n",
    "            lag_time_ = lag_time_.astype(int)\n",
    "            lag_time_ = np.append([0], lag_time_)\n",
    "            lag_time_[lag_time_>3599] = 3599\n",
    "            seq_len = len(q_)\n",
    "\n",
    "            if seq_len >= self.max_seq:\n",
    "                q = q_[-self.max_seq:]\n",
    "                qa = qa_[-self.max_seq:]\n",
    "                task = task_[-self.max_seq:]\n",
    "                lag_time = lag_time_[-self.max_seq:]\n",
    "                part = part_[-self.max_seq:]\n",
    "                tags = tags_[-self.max_seq:]\n",
    "                \n",
    "            else:\n",
    "                q[-seq_len:] = q_\n",
    "                qa[-seq_len:] = qa_          \n",
    "                task[-seq_len:] = task_\n",
    "                lag_time[-seq_len:] = lag_time_\n",
    "                part[-seq_len:] = part_\n",
    "                tags[-seq_len:] = tags_\n",
    "            #print('compute lag time ', target_timestamp, timestamp_[-1])\n",
    "            target_lag_time = int((target_timestamp - timestamp_[-1])/1000)\n",
    "            #print('target_lag_time ', target_lag_time)\n",
    "            if target_lag_time > 3599:\n",
    "                target_lag_time = 3599\n",
    "        q = np.append(q[1:], [target_id])\n",
    "        qa = np.append(qa[1:], [2])\n",
    "        task = np.append(task[1:], [target_task])\n",
    "        lag_time = np.append(lag_time[1:], [target_lag_time])\n",
    "        part = np.append(part[1:], target_part)\n",
    "        tags = np.append(tags[1:], target_tags)\n",
    "        return q, qa, task, lag_time, part, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T06:58:48.368707Z",
     "iopub.status.busy": "2021-01-04T06:58:48.367877Z",
     "iopub.status.idle": "2021-01-04T06:58:48.397708Z",
     "shell.execute_reply": "2021-01-04T06:58:48.397216Z"
    },
    "papermill": {
     "duration": 0.044366,
     "end_time": "2021-01-04T06:58:48.397805",
     "exception": false,
     "start_time": "2021-01-04T06:58:48.353439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import riiideducation\n",
    "\n",
    "env = riiideducation.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T06:58:48.450290Z",
     "iopub.status.busy": "2021-01-04T06:58:48.441685Z",
     "iopub.status.idle": "2021-01-04T06:58:50.023663Z",
     "shell.execute_reply": "2021-01-04T06:58:50.024413Z"
    },
    "papermill": {
     "duration": 1.616418,
     "end_time": "2021-01-04T06:58:50.024606",
     "exception": false,
     "start_time": "2021-01-04T06:58:48.408188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import psutil\n",
    "model.eval()\n",
    "\n",
    "#HDKIM\n",
    "prev_test_df = None\n",
    "#HDKIMHDKIM\n",
    "MAX_SEQ = 180\n",
    "for (test_df, sample_prediction_df) in tqdm(iter_test):\n",
    "    #HDKIM\n",
    "    if (prev_test_df is not None) & (psutil.virtual_memory().percent<90):\n",
    "        prev_test_df['answered_correctly'] = eval(test_df['prior_group_answers_correct'].iloc[0])\n",
    "        prev_test_df = prev_test_df[prev_test_df.content_type_id == False]\n",
    "        prev_group = prev_test_df[['timestamp', 'user_id', 'content_id', 'answered_correctly','task_container_id', 'part', 'tags']].groupby('user_id').apply(\n",
    "            lambda r:\n",
    "            (\n",
    "            r['content_id'].values,\n",
    "            r['answered_correctly'].values, \n",
    "            r['task_container_id'].values,\n",
    "            r['timestamp'].values,\n",
    "            r['part'].values,\n",
    "            r['tags'].values\n",
    "            ))\n",
    "        for prev_user_id in prev_group.index:\n",
    "            prev_group_content, prev_group_ac, prev_group_task,  prev_group_timestamp, prev_part, prev_tags = prev_group[prev_user_id]\n",
    "            if prev_user_id in group.index:\n",
    "                \n",
    "                group[prev_user_id] = (\n",
    "                                       np.append(group[prev_user_id][0],prev_group_content), \n",
    "                                       np.append(group[prev_user_id][1],prev_group_ac),\n",
    "                                       np.append(group[prev_user_id][2],prev_group_task),\n",
    "                                       np.append(group[prev_user_id][3],prev_group_timestamp),\n",
    "                                       np.append(group[prev_user_id][4],prev_part),\n",
    "                                       np.append(group[prev_user_id][5],prev_tags)\n",
    "                                      )\n",
    " \n",
    "            else:\n",
    "                group[prev_user_id] = (prev_group_content, prev_group_ac, prev_group_task, prev_group_timestamp, prev_part, prev_tags)\n",
    "            if len(group[prev_user_id][0])>MAX_SEQ:\n",
    "                new_group_content = group[prev_user_id][0][-MAX_SEQ:]\n",
    "                new_group_ac = group[prev_user_id][1][-MAX_SEQ:]\n",
    "                new_group_task = group[prev_user_id][2][-MAX_SEQ:]\n",
    "                new_group_timestamp = group[prev_user_id][3][-MAX_SEQ:]\n",
    "                new_group_part = group[prev_user_id][4][-MAX_SEQ:]\n",
    "                new_group_tags = group[prev_user_id][5][-MAX_SEQ:]\n",
    "                group[prev_user_id] = (new_group_content, new_group_ac, new_group_task, new_group_timestamp, new_group_part, new_group_tags)\n",
    "    \n",
    "    test_df = test_df.merge(questions[['content_id', 'part', 'tags']], on='content_id', how='left')\n",
    "    prev_test_df = test_df.copy()\n",
    "    test_df = test_df[test_df.content_type_id == False]\n",
    "    #HDKIMHDKIM\n",
    "    \n",
    "\n",
    "    test_dataset = TestDataset(group, test_df, skills)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=51200, shuffle=False)\n",
    "    \n",
    "    outs = []\n",
    "\n",
    "    for item in tqdm(test_dataloader):\n",
    "        q = item[0].to(device).long()\n",
    "        qa = item[1].to(device).long()\n",
    "        task = item[2].to(device).long()\n",
    "        lag_time = item[3].to(device).long()\n",
    "        part = item[4].to(device).long()\n",
    "        tags = item[5].to(device).long()\n",
    "        qa[:, -1] = 2\n",
    "        with torch.no_grad():\n",
    "            output, att_weight = model(q, qa, part, lag_time, part, tags)\n",
    "        \n",
    "        \n",
    "        output = torch.sigmoid(output)\n",
    "        output = output[:, -1]\n",
    "\n",
    "        outs.extend(output.view(-1).data.cpu().numpy())\n",
    "        \n",
    "    test_df['answered_correctly'] =  outs\n",
    "    \n",
    "    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "duration": 299.693788,
   "end_time": "2021-01-04T06:58:50.553840",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-04T06:53:50.860052",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
